{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samkoyun-neo4j/fraud-workshop/blob/main/workshop_notebooks/2-first-party-fraud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKa1NHHnG2H0"
      },
      "source": [
        "# Discovering first party fraud\n",
        "\n",
        "Synthetic identity fraud and first party fraud can be identified by performing entity link analysis to detect identities linked to other identities via shared PII.\n",
        "\n",
        "There are three types of personally identifiable information (PII) in this dataset - __SSN, Email and Phone Number__\n",
        "\n",
        "Our hypothesis is that <u>clients who share identifiers are suspicious and have a higher potential to commit fraud. However, all shared identifier links are not suspicious</u>, for example, two people sharing an email address. Hence, we compute a fraud score based on shared PII relationships and label the top X percentile clients as fraudsters. \n",
        "\n",
        "This pattern can be easily discovered but first, let's connect to our database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Neo4j GDS Python Client\n",
        "import sys\n",
        "!{sys.executable} -m pip install graphdatascience dotenv\n",
        "\n",
        "# Import our GDS entry point\n",
        "from graphdatascience import GraphDataScience\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# (Desktop) Load environment variables from a .env file\n",
        "# load_dotenv(override=True)\n",
        "# gds = GraphDataScience(os.environ[\"NEO4J_URI\"], auth=(os.environ[\"NEO4J_USER\"], os.environ[\"NEO4J_PASS\"]))\n",
        "\n",
        "# (Colab) Directly provide connection details (Replace the placeholders below)\n",
        "gds = GraphDataScience(\"uri\", auth=(\"neo4j\", \"password\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's check who's sharing PIIs;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = gds.run_cypher(\n",
        "    \"\"\"\n",
        "    MATCH (c1:Client)-[:HAS_EMAIL|HAS_PHONE|HAS_SSN]->(n)<-[:HAS_EMAIL|HAS_PHONE|HAS_SSN]-(c2:Client)\n",
        "    WHERE elementId(c1) < elementId(c2)\n",
        "    RETURN c1.name as Client1, c2.name as Client2, count(*) AS SharedIdentifiers\n",
        "    ORDER BY SharedIdentifiers DESC\n",
        "    LIMIT 10;\n",
        "    \"\"\"\n",
        ")\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And this shows how many clients are sharing PIIs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = gds.run_cypher(\n",
        "    \"\"\"\n",
        "    MATCH (c1:Client)-[:HAS_EMAIL|HAS_PHONE|HAS_SSN]->(n) <-[:HAS_EMAIL|HAS_PHONE|HAS_SSN]-(c2:Client)\n",
        "    WHERE elementId(c1) < elementId(c2)\n",
        "    RETURN count(DISTINCT c1.id) AS `PII sharing clients`;\n",
        "    \"\"\"\n",
        ")\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Let's do some data Graph Data Science !\n",
        "\n",
        "Now that our graph is constructed and filled with data, we can use Neo4j Graph Data Science to look for anomolies in the graph that are often associated with fraudulent behaviour.\n",
        "\n",
        "One of the unique features of the Neo4j platform is that GDS can be used on projections generated directly from a live transactional database. Obviously this is critical for quickly identifying fraud as it occurs as opposed to performing batch post analysis on stale data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Projection\n",
        "\n",
        "Our first step is to define a new graph projection. Projections are created in memory from live data and may be used immediately for analysis. Our first graph projection will be used to analyse client identification data provided at signup. All projections must be uniquely named, here we are checking if our 'firstPartyFraud' graph already exists and if so we can drop and recreate it.\n",
        "\n",
        "<img src=\"../img/graph_projection.png\" alt=\"Graph Projection\" width=\"60%\" title=\"Graph Projection\">  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By checking connections among clients based on the identity information from their accounts, we can identify potentially fake profiles and shady clients. Our projection only needs to contain the slice of data pertinent to the type of analysis we are performing. Projections may also be created directly from a Cypher query to target even more specific data when required, however in this case we are using a 'native projection' based on the types of nodes and relationships only. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtUtta8EqVEf",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# My first graph project name to use wcc algorithm\n",
        "graphName = 'firstPartyFraud'\n",
        "\n",
        "# Remove existing projection with the same name, in case of a re run of the notebook\n",
        "if gds.graph.exists(graphName).exists:\n",
        "    gds.graph.drop(gds.graph.get(graphName))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can start with a memory estimate of our projection, this is an optional yet useful step for ensuring the size of our GDS instance is sufficient for the task at hand. No projection is created here, just some data estimating the size of the in memory footprint it would create. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCqEbrWrG2H0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "gds.graph.project.estimate(\n",
        "    ['Client', 'SSN', 'Email', 'Phone'],     # Nodes to be added in the projection\n",
        "    ['HAS_SSN', 'HAS_EMAIL', 'HAS_PHONE']\n",
        ")   # Relationships to be added in the projection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwaXlsPmG2H0"
      },
      "source": [
        "We can see from the output that projections are highly optimised and very compact in memory as they contain only the information we request (in this case only selected nodes and their connections, no unnecessary properties). \n",
        "\n",
        "### Next, create the projection to be used\n",
        "\n",
        "Once we are happy with the estimate, we use very similar syntax to create the actual projection. Here we are using __native graph projection__ and receiving a reference as the variable 'projection'. In addition projectionPandas is returned to provide some statistics of the creation and the projection itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jg8EWiKaqVHO",
        "tags": []
      },
      "outputs": [],
      "source": [
        "projection, projectionPandas = gds.graph.project(\n",
        "    graphName,\n",
        "    ['Client', 'SSN', 'Email', 'Phone'],\n",
        "    ['HAS_SSN', 'HAS_EMAIL', 'HAS_PHONE']\n",
        ")\n",
        "\n",
        "projectionPandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below is the graph projection we just created.\n",
        "\n",
        "<img src=\"../img/similarity_projection.png?raw=1\" alt=\"first party projection\" width=\"75%\" title=\"first party projection\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUFz0bP0G2H0"
      },
      "source": [
        "## Fraud Communitiy\n",
        "\n",
        "### Selecting our algorithm - Weakly Connected Components\n",
        "\n",
        "One hallmark of first party fraud is re-use of stolen personal data in the creation of multiple fraudulent accounts. Often bad actors purchase the same stolen information and it will therefore present as a number of accounts with various combinations of the same information.  \n",
        "\n",
        "When you look at the information shared by multiple accounts as a graph, groups of fraudulent accounts tend to form a strongly connected subgraph. Legitimate accounts are typically isolated or only reuse some information (maybe a phone number or email in common) whereas large groups of clients with many connections are often associated with stolen information.\n",
        "\n",
        "The [Weakly Connected Components](https://neo4j.com/docs/graph-data-science/current/algorithms/wcc/) algorithm is perfect for this purpose as it identifies these connected groups of users that are weakly connected to the rest of the user graph. If we can find larger groups of connected clients using WCC, there is a strong chance they are related to stolen data reuse and first party fraud.\n",
        "\n",
        "\n",
        "### Running WCC in streaming mode\n",
        "\n",
        "Algorithms can be run in a number of modes depending on the use case. The streaming mode returns the result of an algorithm as a stream, just like the return of a cypher query. Let's try executing the WCC algorithm on our new projection in the streaming mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7dls0G-qVMN",
        "tags": []
      },
      "outputs": [],
      "source": [
        "result = gds.wcc.stream(projection)\n",
        "result.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ydys7P2UG2H1",
        "tags": []
      },
      "outputs": [],
      "source": [
        "result.groupby(['componentId']).count().sort_values('nodeId', ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t432mbgG2H1"
      },
      "source": [
        "As we can see WCC streaming mode returns the component (or group) ID for each of the nodes represented in the projection. Just listing it didnt give very useful information however we can count the nodes in each group and find the ID of the largest groups discovered by the WCC algorithm (note these counts include all nodes in the group including the identifying data nodes).\n",
        "\n",
        "\n",
        "### Writing group information directly to the database\n",
        "\n",
        "While streaming mode is useful for identifying and analysing groups directly in the notebook, we may want to actually write group membership information into a property on the node itself to enable further analysis (either in Bloom or using it in a subsequent algorithm execution).\n",
        "\n",
        "We can use the write mode directly on algorithm execution. In this case the WCC algorithm will write the componentId directly to the node into a property of our choice. This works well when we are happy for all nodes to have data written.\n",
        "\n",
        "\n",
        "In this example, we intentionally apply additional constraints before labelling first-party fraud groups. Rather than writing a `firstPartyFraudGroup` property for every connected component, we only assign this property when a group contains more than *three* clients. This helps reduce false positives by filtering out small or incidental clusters that are unlikely to represent organised fraud. In practice, you could further refine this logic by excluding benign shared identifiers, such as email addresses or phone numbers commonly shared among family members. These types of exclusions are highly domain-specific and can be layered in as additional conditions.\n",
        "\n",
        "To support this **selective labelling**, we run the WCC algorithm in `stream` mode. This allows us to inspect the algorithm’s output directly in Cypher, apply our own filtering logic, and then explicitly write the `firstPartyFraudGroup` property using a SET clause.\n",
        "\n",
        "Finally, note that this process targets only nodes with the `Client` label, as these are the entities we want to analyse and group in the context of first-party fraud.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = gds.run_cypher(\n",
        "    \"\"\"\n",
        "    CALL gds.wcc.stream(\n",
        "        $graphName,\n",
        "        {\n",
        "            nodeLabels: ['Client', 'SSN', 'Email', 'Phone'],\n",
        "            relationshipTypes: ['HAS_SSN', 'HAS_EMAIL', 'HAS_PHONE']\n",
        "        }\n",
        "    )\n",
        "    YIELD componentId, nodeId\n",
        "    WHERE 'Client' IN labels(gds.util.asNode(nodeId))   // Filter only Client nodes\n",
        "    WITH componentId, count(nodeId) as communitySize\n",
        "    WHERE communitySize > 3                             // Filter communities larger than 3 members\n",
        "    RETURN componentId, communitySize\n",
        "    ORDER BY communitySize DESC;\n",
        "    \"\"\", \n",
        "    params= {'graphName': graphName}\n",
        ")\n",
        "result.head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's write this to the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2NF86MlzHVR",
        "tags": []
      },
      "outputs": [],
      "source": [
        "gds.run_cypher(\n",
        "    \"\"\"\n",
        "    CALL gds.wcc.stream($graphName) \n",
        "    YIELD nodeId, componentId\n",
        "    WHERE 'Client' IN labels(gds.util.asNode(nodeId))\n",
        "    WITH componentId, collect(gds.util.asNode(nodeId)) AS clients\n",
        "    WITH componentId, size(clients) AS communitySize, clients\n",
        "    WHERE communitySize > 3                   \n",
        "    UNWIND clients AS client\n",
        "    SET client.firstPartyFraudGroup = componentId\n",
        "    \"\"\", \n",
        "    params= {'graphName': graphName}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtkJVJxHG2H1"
      },
      "source": [
        "### Take a closer look at our potential fraud groups\n",
        "\n",
        "Now that we have identified our possible fraud groups and have a property to identify which group (if any) that each client is a member of, we can use this data to start looking closer at the larger identified groups. We  also create an index on our new fraud_group property to make Cypher queries referencing this property even faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d0hPxuYzHX3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Create an index on the new property just created by the wcc algorithm on Clients\n",
        "gds.run_cypher(\"CREATE INDEX ClientFraudIndex IF NOT EXISTS FOR (c:Client) on c.firstPartyFraudGroup;\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFvM5X4KzHaJ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Look at the community created by the algorithm\n",
        "# We can see the biggest community has 10 elements\n",
        "result = gds.run_cypher(\"\"\"\n",
        "  MATCH (c:Client) WHERE c.firstPartyFraudGroup IS NOT NULL\n",
        "  WITH c.firstPartyFraudGroup AS groupId, collect(c.id) AS members\n",
        "  WITH groupId, size(members) AS groupSize\n",
        "  WITH collect(groupId) AS groupsOfSize, groupSize\n",
        "  RETURN groupSize, size(groupsOfSize) AS numOfGroups, groupsOfSize as FraudGroupIds\n",
        "  ORDER BY groupSize DESC;\n",
        "\"\"\")\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can run below Cypher on browser to visualise the suspicious communities;\n",
        "\n",
        "```cypher\n",
        "MATCH (c:Client)\n",
        "WITH c.firstPartyFraudGroup AS fpGroupID, count(c) AS groupSize WHERE groupSize >= 9\n",
        "WITH collect(fpGroupID) AS fraudRings\n",
        "MATCH p=(c:Client)-[:HAS_SSN|HAS_EMAIL|HAS_PHONE]->()\n",
        "WHERE c.firstPartyFraudGroup IN fraudRings\n",
        "RETURN p\n",
        "```\n",
        "\n",
        "<img src=\"../img/suspicious_communities.png?raw=1\" alt=\"firstpartygroups\" width=\"75%\" title=\"firstpartygroups\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Labelling FirstPartyFraud\n",
        "\n",
        "Now we can label the suspects of the first party fraud. We could simply apply the label to all clients who are part of potential fraud communities but not everyone involved in the fraud communities are equally risky. We hypothesize that clients that are connected to highly reused identifiers have higher potential to commit fraud.\n",
        "\n",
        "We will use graph algorithms to score clients based on the number of common connections and rank them to select the top few suspicious clients and label them as fraudsters.\n",
        "\n",
        "### 1. Find common connections via Node Similarity\n",
        "The Node Similarity algorithm compares a set of nodes(`Client`) based on the nodes(`SSN`, `Phone`, `Email`) they are connected to.\n",
        "\n",
        "#### 1-1. Projection\n",
        "\n",
        "We will use the same projection `firstPartyFraud` we created earlier, which is represented as below.\n",
        "\n",
        "<img src=\"../img/similarity_projection.png?raw=1\" alt=\"first party projection\" width=\"75%\" title=\"first party projection\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1-2. Project `SIMILAR_TO` relationships between Clients\n",
        "\n",
        "We will add `SIMILAR_TO` relationships to the projection so we could use this to measure the fraud score later. Note that we're using `mutate` mode instead of `write` mode. \n",
        "In mutate mode, algorithm outputs (such as centrality scores, community IDs, or derived weights) are attached only to the projected graph, allowing them to directly influence subsequent analytics steps—such as re-weighting relationships, filtering nodes, or seeding another algorithm—within the same workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = gds.run_cypher(\n",
        "    \"\"\"\n",
        "    CALL gds.nodeSimilarity.mutate('firstPartyFraud', {\n",
        "        mutateRelationshipType: 'SIMILAR_TO',\n",
        "        mutateProperty: 'jaccardScore'\n",
        "    })\n",
        "    YIELD nodesCompared, relationshipsWritten\n",
        "    RETURN nodesCompared, relationshipsWritten\n",
        "    \"\"\"\n",
        ")\n",
        "result.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Who is sharing PIIs the most?\n",
        "\n",
        "We compute first party fraud score using weighted degree centrality algorithm.\n",
        "\n",
        "In this step, we compute and assign fraud score (firstPartyFraudScore) to clients in the clusters identified in previous steps based on SIMILAR_TO relationships weighted by jaccardScore\n",
        "\n",
        "Weighted degree centrality algorithm add up similarity scores (jaccardScore) on the incoming SIMILAR_TO relationships for a given node in a cluster and assign the sum as the corresponding firstPartyFraudScore. This score represents clients who are similar to many others in the cluster in terms of sharing identifiers. Higher firstPartyFraudScore represents greater potential for committing fraud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = gds.run_cypher(\n",
        "    \"\"\"\n",
        "    CALL gds.degree.stream('firstPartyFraud',\n",
        "        {\n",
        "            relationshipTypes: ['SIMILAR_TO'],\n",
        "            relationshipWeightProperty: 'jaccardScore'\n",
        "        })\n",
        "    YIELD nodeId, score\n",
        "    WITH gds.util.asNode(nodeId) AS client, score\n",
        "    WHERE score > 0\n",
        "    SET client.firstPartyFraudScore = score;\n",
        "    \"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Label the `FirstPartyFraudster`\n",
        "\n",
        "We could label Clients with fraud score of 70% percentile and above to be `FirstPartyFraudster`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = gds.run_cypher(\n",
        "    \"\"\"\n",
        "    MATCH(c:Client)\n",
        "    WHERE c.firstPartyFraudScore IS NOT NULL\n",
        "    WITH percentileCont(c.firstPartyFraudScore, 0.50) AS firstPartyFraudThreshold\n",
        "\n",
        "    MATCH(c:Client)\n",
        "    WHERE c.firstPartyFraudScore > firstPartyFraudThreshold\n",
        "    SET c:FirstPartyFraudster;\n",
        "    \"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq-NlOB7G2H1"
      },
      "source": [
        "## Using Bloom to visualise fraud groups\n",
        "\n",
        "<img src=\"../img/opening_bloom.png?raw=1\" alt=\"Opening Bloom\" width=\"75%\"  title=\"Opening Bloom\">\n",
        "\n",
        "Lets take a look at some of these communities in Neo4j Bloom.  We will download and import the perspective from the bloom directory of the workshop github repository.\n",
        "\n",
        "<a id=\"raw-url\" href=\"../bloom/graph_summit_workshop.json\">Click here to download Bloom Perspective</a>\n",
        "\n",
        "Now use the import feature button in bloom to add the perspective to our new Bloom instance.\n",
        "\n",
        "<img src=\"../img/import_perspective.png?raw=1\" alt=\"Import Bloom Perspective\" width=\"75%\" title=\"Import Bloom Perspective\">\n",
        "\n",
        "We can now click on the perspective to open it and explore the dataset further, for example using the search bar for \"Find client with name Carson Wynn\" and then using a scene action (right click) on Carson's node to \"Show suspected fraud group\" can provides us with information about this users common data with others in the group.\n",
        "\n",
        "Try the following search phrases using Bloom\n",
        "\n",
        "* Find client with name John Kirby\n",
        "  * Select and right click on John's node to use scene actions\n",
        "* Show largest first party fraud groups\n",
        "* Find client with name Carson Wynn\n",
        "  * Select and right click on Carson to explain fraud group\n",
        "\n",
        "<img src=\"../img/first_party_fraud.png?raw=1\" alt=\"Fraud group 4162\" width=\"75%\" title=\"Fraud group 4162\">\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
